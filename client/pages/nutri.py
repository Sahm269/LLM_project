import streamlit as st
import os
import time
from server.mistral.mistralapi import MistralAPI
from server.security.prompt_guard import Guardrail
import asyncio
from typing import List, Dict
from datetime import datetime
from server.db.dbmanager import (
    load_conversations,
    load_messages, 
    update_conversation,
    create_conversation,
    save_message,
    get_conversation_title,
    update_conversation_title,
    delete_conversation,
    load_chatbot_suggestions,
    save_chatbot_suggestions
)

# ğŸ”¹ Chargement des variables de session pour Ã©viter les rechargements inutiles
if "id_conversation" not in st.session_state:
    st.session_state.id_conversation = None

if "mistral_model" not in st.session_state:
    st.session_state["mistral_model"] = "mistral-large-latest"

if "messages" not in st.session_state:
    st.session_state.messages = []  # Initialise l'historique des messages




# ğŸ”¹ Initialisation unique de MistralAPI
if "mistral_instance" not in st.session_state:
    print("ğŸ”„ Initialisation de MistralAPI...")
    st.session_state.mistral_instance = MistralAPI(model=st.session_state["mistral_model"])
    print("âœ… MistralAPI initialisÃ© avec succÃ¨s.")

mistral = st.session_state.mistral_instance  # RÃ©cupÃ©rer l'instance stockÃ©e

# ğŸ”¹ Initialisation de la sÃ©curitÃ© (Guardrail)
try:
    guardrail = Guardrail()
except Exception as e:
    st.error(f"âŒ Guardrail introuvable. Veuillez relancer le conteneur. DÃ©tails : {e}")
    st.stop()

# ğŸ”¹ Chargement de la base de donnÃ©es
db_manager = st.session_state["db_manager"]
user_id = st.session_state["user_id"]

if "chatbot_suggestions" not in st.session_state:
    st.session_state["chatbot_suggestions"] = load_chatbot_suggestions(db_manager, user_id)

# ğŸ”¹ Sidebar : Bouton "â• Nouveau chat" en haut
st.sidebar.title("ğŸ—‚ï¸ Historique")
if st.sidebar.button("â• Nouveau chat"):
    title = "Nouvelle conversation"
    new_conversation_id = create_conversation(db_manager, title, user_id)
    st.session_state.id_conversation = new_conversation_id
    st.session_state.messages = []  
    st.rerun()

# ğŸ”¹ Charger l'historique des conversations
conversation_history = load_conversations(db_manager, user_id) or []

# ğŸ”¹ Sidebar : Affichage de l'historique des conversations avec bouton de suppression
for index, conversation in enumerate(conversation_history):
    id_conversation = conversation['id_conversation']
    title = conversation['title']
    key = f"conversation_{id_conversation}_{index}"  # ClÃ© unique

    col1, col2 = st.sidebar.columns([0.8, 0.2])  # ğŸ”¹ Disposition pour aligner le bouton de suppression

    with col1:
        if "id_conversation" in st.session_state and st.session_state.id_conversation == id_conversation:
            st.button(f"ğŸŸ¢ {title}", key=key, disabled=True)
        else:
            if st.button(title, key=key):
                st.session_state.id_conversation = id_conversation
                st.session_state.messages = load_messages(db_manager, id_conversation)
                update_conversation(db_manager, id_conversation=st.session_state.id_conversation, id_utilisateur=user_id)
                st.rerun()

    with col2:
        if st.button("ğŸ—‘ï¸", key=f"delete_{id_conversation}"):  # ğŸ”¥ Bouton de suppression
            delete_conversation(db_manager, id_conversation)
            st.rerun()  # RafraÃ®chir aprÃ¨s suppression

# ğŸ”¹ Affichage des messages prÃ©cÃ©dents dans l'interface
for message in st.session_state.messages:
    timestamp = message["timestamp"]
    latency = message["temps_traitement"]
    latency_text = f"â³ {latency} sec" if latency is not None else ""

    if message["role"] == "user":
        with st.chat_message("user"):
            st.markdown(message["content"])
            st.caption(f"ğŸ“… {timestamp} {latency_text}")

    elif message["role"] == "assistant":
        with st.chat_message("assistant", avatar="client/assets/avatar_bot_big.jpg"):
            st.markdown(message["content"])
            st.caption(f"ğŸ“… {timestamp} {latency_text}")  # ğŸ”¹ Ajout de l'heure et de la latence


# ğŸ”¹ Interface utilisateur - Zone d'entrÃ©e utilisateur
if prompt := st.chat_input("DÃ®tes quelque-chose"):

    # ğŸ”¸ VÃ©rifier la sÃ©curitÃ© du message
    is_safe = guardrail.analyze_query(prompt)

    # ğŸ”¸ Afficher immÃ©diatement le message de l'utilisateur
    with st.chat_message("user"):
        st.markdown(prompt)

    if st.session_state.id_conversation is None:
        # GÃ©nÃ©rer un titre basÃ© sur le premier message
        title = mistral.auto_wrap(text=prompt, temperature=0.5)
        st.session_state.id_conversation = create_conversation(db_manager, title, user_id)
    else:
        # VÃ©rifier si le titre est encore "Nouvelle conversation" et le mettre Ã  jour si nÃ©cessaire
        current_title = get_conversation_title(db_manager, st.session_state.id_conversation)
        if current_title == "Nouvelle conversation":
            new_title = mistral.auto_wrap(text=prompt, temperature=0.5)
            update_conversation_title(db_manager, st.session_state.id_conversation, new_title)

    # ğŸ”¸ Ajouter le message Ã  l'historique et l'enregistrer dans la base de donnÃ©es
    st.session_state.messages.append({"role": "user", "content": prompt,  "temps_traitement":None, "timestamp":datetime.now().strftime("%Y-%m-%d %H:%M:%S")})
    save_message(db_manager, st.session_state.id_conversation, role="user", content=prompt, temps_traitement=None)

    # ğŸ”¸ Si le message est interdit, afficher l'alerte mais NE PAS l'envoyer Ã  Mistral
    if not is_safe:
        st.warning("âš ï¸ Votre message ne respecte pas nos consignes.")
        st.stop()  # ArrÃªter l'exÃ©cution ici pour ne PAS envoyer Ã  Mistral

    retries = 0
    max_retries = 3

    # ğŸ”¹ GÃ©nÃ©rer une rÃ©ponse avec Mistral et RAG
    with st.chat_message("assistant", avatar="client/assets/avatar_bot_big.jpg"):
        retries = 0
        max_retries = 3
        while retries < max_retries:
            response = ""
            response_placeholder = st.empty()
            try:
                start_time = time.time()  # ğŸ”¹ DÃ©but du chronomÃ¨tre

                print("ğŸ”„ GÃ©nÃ©ration de rÃ©ponse en cours...")
                stream_response = mistral.stream(st.session_state.messages, temperature=0.5)

                for chunk in stream_response:
                    response += chunk.data.choices[0].delta.content
                    response_placeholder.markdown(response)
                    time.sleep(0.03)
                
                # ğŸ”¹ VÃ©rifier si la rÃ©ponse contient une suggestion de recette
                
                # ğŸ”¹ VÃ©rifier si la rÃ©ponse contient des suggestions de recettes
                keywords = ["recette", "plat", "prÃ©parer", "ingrÃ©dients"]

                for word in keywords:
                    if word in response.lower():
                        try:
                            # ğŸ”¹ Extraire plusieurs titres de recettes
                            suggested_recipes = mistral.extract_multiple_recipes(text=response, temperature=0.3)

                            # VÃ©rifier et initialiser la liste des suggestions
                            if "chatbot_suggestions" not in st.session_state:
                                st.session_state["chatbot_suggestions"] = []

                            # Ajouter uniquement les recettes qui ne sont pas dÃ©jÃ  stockÃ©es
                            new_recipes = [recipe for recipe in suggested_recipes if recipe not in st.session_state["chatbot_suggestions"]]
                            
                            if new_recipes:
                                st.session_state["chatbot_suggestions"].extend(new_recipes)  # Ajouter plusieurs recettes
                                print(f"âœ… {len(new_recipes)} nouvelles suggestions ajoutÃ©es.")
                                
                                # ğŸ”¹ Sauvegarder les suggestions dans la BDD
                                save_chatbot_suggestions(db_manager, user_id, new_recipes)
                        except Exception as e:
                            print(f"âŒ Erreur lors de l'extraction des suggestions : {e}")

                        break  # On ne veut ajouter qu'une seule suggestion par rÃ©ponse




                end_time = time.time()  # ğŸ”¹ Fin du chronomÃ¨tre
                latency = round(end_time - start_time, 2)  # ğŸ”¹ Calcul de la latence

                print(f"âœ… RÃ©ponse gÃ©nÃ©rÃ©e en {latency} secondes.")
            except Exception as e:
                if hasattr(e, "status_code") and e.status_code == 429:
                    retries += 1
                    wait_time = 2 ** retries  
                    stream_response = None
                    print(f"âš ï¸ Rate limit atteint. Nouvel essai dans {wait_time} secondes...")
                    time.sleep(wait_time)
                else:
                    st.error(f"âŒ Erreur : Impossible de traiter votre demande. DÃ©tails : {str(e)}")
                    response_placeholder.markdown("âŒ Erreur lors de la gÃ©nÃ©ration de la rÃ©ponse.")
                    st.stop()

            if stream_response is not None:
                break  

        if retries >= max_retries:
            st.error("âŒ Impossible d'obtenir une rÃ©ponse aprÃ¨s plusieurs tentatives.")
            response = "âŒ Erreur : Limite de requÃªtes atteinte."

        # ğŸ”¹ Enregistrer la rÃ©ponse de l'assistant
        st.session_state.messages.append({"role": "assistant", "content": response, "temps_traitement":latency, "timestamp":datetime.now().strftime("%Y-%m-%d %H:%M:%S")})
        save_message(db_manager, st.session_state.id_conversation, role="assistant", content=response, temps_traitement=latency)
